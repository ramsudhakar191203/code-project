import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.utils import load_img, img_to_array
from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, BatchNormalization
from tensorflow.keras.applications import DenseNet121, MobileNetV2
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
from tensorflow.keras import optimizers, regularizers
import albumentations as A
import os
# Set up directories
train_dir = '/content/Alzheimers_Dataset/Combined Dataset/train'
val_dir = '/content/Alzheimers_Dataset/Combined Dataset/test'

import albumentations as A

augmentation = A.Compose([
    A.Resize(height=256, width=256),  # Ensure all images have a fixed size first
    A.RandomCrop(height=224, width=224),  # Then randomly crop to 224x224
    A.Rotate(limit=20),
    A.HorizontalFlip(),
    A.RandomBrightnessContrast(),
    A.GaussianBlur(),
    A.CLAHE(),
])
# ‚úÖ Fix: Implement Mixup in Keras
def mixup(x, y, alpha=0.2):
    """Applies Mixup Augmentation"""
    lam = np.random.beta(alpha, alpha)
    batch_size = tf.shape(x)[0]
    index = tf.random.shuffle(tf.range(batch_size))

    mixed_x = lam * x + (1 - lam) * tf.gather(x, index)
    mixed_y = lam * y + (1 - lam) * tf.gather(y, index)

    return mixed_x, mixed_y

class MixupGenerator(tf.keras.utils.Sequence):
    def __init__(self, generator, alpha=0.2):
        self.generator = generator
        self.alpha = alpha

    def __len__(self):
        return len(self.generator)

    def __getitem__(self, idx):
        x, y = self.generator[idx]
        return mixup(x, y, self.alpha)

# ‚úÖ Fix: Data Generators
batch_size = 32
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)
test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    train_dir, target_size=(224, 224), batch_size=batch_size, class_mode='categorical'
)

validation_generator = test_datagen.flow_from_directory(
    val_dir, target_size=(224, 224), batch_size=batch_size, class_mode='categorical'
)
# ‚úÖ Fix: Learning Rate Scheduler (Use Exponential Decay)
lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate=0.0005,
    decay_steps=1000,
    decay_rate=0.9
)
# ‚úÖ Fix: Model Architecture
densenet_base = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
mobilenet_base = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
def build_model(base_model):
    x = GlobalAveragePooling2D()(base_model.output)
    x = Dropout(0.5)(x)
    x = Dense(4, activation='softmax', kernel_regularizer=regularizers.l2(0.01))(x)

    model = Model(inputs=base_model.input, outputs=x)

    # Freeze initial layers
    for layer in base_model.layers[:100]:
        layer.trainable = False

    model.compile(
        optimizer=optimizers.Adam(learning_rate=lr_schedule),
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )
    return model

densenet_model = build_model(densenet_base)
mobilenet_model = build_model(mobilenet_base)
# ‚úÖ Fix: Callbacks
early_stop = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)
checkpoint_densenet = ModelCheckpoint('densenet_best.h5', monitor='val_accuracy', save_best_only=True)
checkpoint_mobilenet = ModelCheckpoint('mobilenet_best.h5', monitor='val_accuracy', save_best_only=True)
# ‚úÖ Fix: Train Models with Mixup
train_generator_with_mixup = MixupGenerator(train_generator, alpha=0.2)
# Train DenseNet Model
print("Training DenseNet model...")
densenet_history = densenet_model.fit(
    train_generator,
    epochs=50,  # Train for more epochs
    validation_data=validation_generator,
    callbacks=[early_stop, reduce_lr, checkpoint_densenet]
)
densenet_model.save('final_densenet_model.h5')
densenet_eval = densenet_model.evaluate(validation_generator)
print(f"DenseNet Model - Validation Loss: {densenet_eval[0]}, Validation Accuracy: {densenet_eval[1]}")
print("Training MobileNet model...")
mobilenet_model.fit(
    train_generator_with_mixup,
    epochs=50,
    validation_data=validation_generator,
    callbacks=[early_stop, checkpoint_mobilenet]
)
mobilenet_eval = mobilenet_model.evaluate(validation_generator)
print(f"MobileNet Model - Validation Loss: {mobilenet_eval[0]}, Accuracy: {mobilenet_eval[1]}")
# ‚úÖ Fix: Ensemble Model (Weighted Averaging)
def ensemble_predict(image_path, W1=0.6, W2=0.4):
    img = load_img(image_path, target_size=(224, 224))
    img_array = img_to_array(img) / 255.0
    img_array = np.expand_dims(img_array, axis=0)

    pred_densenet = densenet_model.predict(img_array)
    pred_mobilenet = mobilenet_model.predict(img_array)

    final_pred = (W1 * pred_densenet) + (W2 * pred_mobilenet)
    return np.argmax(final_pred, axis=1)
# ‚úÖ Fix: Test-Time Augmentation (TTA)
def tta_predict(image_path, num_augmentations=5, W1=0.6, W2=0.4):
    img = load_img(image_path, target_size=(224, 224))
    img_array = img_to_array(img) / 255.0

    preds_densenet = []
    preds_mobilenet = []

    for _ in range(num_augmentations):
        aug_img = augmentation(image=img_array)['image']
        aug_img = np.expand_dims(aug_img, axis=0)

        preds_densenet.append(densenet_model.predict(aug_img))
        preds_mobilenet.append(mobilenet_model.predict(aug_img))

    avg_pred_densenet = np.mean(preds_densenet, axis=0)
    avg_pred_mobilenet = np.mean(preds_mobilenet, axis=0)

    final_pred = (W1 * avg_pred_densenet) + (W2 * avg_pred_mobilenet)
    return np.argmax(final_pred, axis=1)
# ‚úÖ Fix: Example Usage
image_path = r'/content/Alzheimers_Dataset/Combined Dataset/test/Moderate Impairment/14.jpg'
ensemble_class = ensemble_predict(image_path)
tta_class = tta_predict(image_path)

print(f"Ensemble Predicted Class: {ensemble_class}")
print(f"TTA Predicted Class: {tta_class}")

print("Training completed and models saved!")
import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import pandas as pd

# ‚úÖ Load DenseNet model
densenet_model = load_model('densenet_best.h5')

# ‚úÖ Define class labels (Ensure these match your training labels)
CLASS_LABELS = ["Mild Impairment", "Moderate Impairment", "No Impairment", "Very Mild Impairment"]

# ‚úÖ Image preprocessing function
def preprocess_image(image_path):
    """Loads and preprocesses image for DenseNet inference."""
    img = load_img(image_path, target_size=(224, 224))  # Resize
    img_array = img_to_array(img) / 255.0  # Normalize
    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension
    return img_array

# ‚úÖ Function to test DenseNet on complete test dataset
def test_densenet_on_directory(test_dir):
    """Tests DenseNet on all images in the test directory and computes accuracy."""
    true_labels = []
    predicted_labels = []

    for class_label in os.listdir(test_dir):  # Iterate over class folders
        class_dir = os.path.join(test_dir, class_label)
        if not os.path.isdir(class_dir):  # Skip non-directory files
            continue

        print(f"üîç Testing images from class: {class_label}...")
        for image_name in os.listdir(class_dir):
            image_path = os.path.join(class_dir, image_name)

            # Skip non-image files
            if not image_path.lower().endswith(('.png', '.jpg', '.jpeg')):
                continue

            # Preprocess image
            img_array = preprocess_image(image_path)

            # Make prediction
            pred_densenet = densenet_model.predict(img_array)
            predicted_class = np.argmax(pred_densenet, axis=1)[0]
            predicted_label = CLASS_LABELS[predicted_class]

            # Append results
            true_labels.append(class_label)
            predicted_labels.append(predicted_label)

    # ‚úÖ Compute Accuracy
    accuracy = accuracy_score(true_labels, predicted_labels)
    print("\n‚úÖ DenseNet Accuracy:", round(accuracy * 100, 2), "%")

    # ‚úÖ Generate Classification Report
    print("\nüìä Classification Report:")
    print(classification_report(true_labels, predicted_labels, target_names=CLASS_LABELS))

    # ‚úÖ Confusion Matrix
    print("\nüîπ Confusion Matrix:")
    print(confusion_matrix(true_labels, predicted_labels))

    # ‚úÖ Save results to CSV
    results_df = pd.DataFrame({'True Label': true_labels, 'Predicted Label': predicted_labels})
    results_df.to_csv('densenet_test_results.csv', index=False)
    print("\nüìÅ Results saved as 'densenet_test_results.csv'")

# ‚úÖ Run testing
test_dir = "/content/Alzheimers_Dataset/Combined Dataset/test"  # Replace with your actual test dataset path
test_densenet_on_directory(test_dir)

import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import pandas as pd

# ‚úÖ Load MobileNet model
mobilenet_model = load_model('mobilenet_best.h5')

# ‚úÖ Define class labels (Ensure these match your training labels)
CLASS_LABELS = ["Mild Impairment", "Moderate Impairment", "No Impairment", "Very Mild Impairment"]

# ‚úÖ Image preprocessing function
def preprocess_image(image_path):
    """Loads and preprocesses image for MobileNet inference."""
    img = load_img(image_path, target_size=(224, 224))  # Resize
    img_array = img_to_array(img) / 255.0  # Normalize
    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension
    return img_array

# ‚úÖ Function to test MobileNet on complete test dataset
def test_mobilenet_on_directory(test_dir):
    """Tests MobileNet on all images in the test directory and computes accuracy."""
    true_labels = []
    predicted_labels = []

    for class_label in os.listdir(test_dir):  # Iterate over class folders
        class_dir = os.path.join(test_dir, class_label)
        if not os.path.isdir(class_dir):  # Skip non-directory files
            continue

        print(f"üîç Testing images from class: {class_label}...")
        for image_name in os.listdir(class_dir):
            image_path = os.path.join(class_dir, image_name)

            # Skip non-image files
            if not image_path.lower().endswith(('.png', '.jpg', '.jpeg')):
                continue

            # Preprocess image
            img_array = preprocess_image(image_path)

            # Make prediction
            pred_mobilenet = mobilenet_model.predict(img_array)
            predicted_class = np.argmax(pred_mobilenet, axis=1)[0]
            predicted_label = CLASS_LABELS[predicted_class]

            # Append results
            true_labels.append(class_label)
            predicted_labels.append(predicted_label)

    # ‚úÖ Compute Accuracy
    accuracy = accuracy_score(true_labels, predicted_labels)
    print("\n‚úÖ MobileNet Accuracy:", round(accuracy * 100, 2), "%")

    # ‚úÖ Generate Classification Report
    print("\nüìä Classification Report:")
    print(classification_report(true_labels, predicted_labels, target_names=CLASS_LABELS))

    # ‚úÖ Confusion Matrix
    print("\nüîπ Confusion Matrix:")
    print(confusion_matrix(true_labels, predicted_labels))

    # ‚úÖ Save results to CSV
    results_df = pd.DataFrame({'True Label': true_labels, 'Predicted Label': predicted_labels})
    results_df.to_csv('mobilenet_test_results.csv', index=False)
    print("\nüìÅ Results saved as 'mobilenet_test_results.csv'")

# ‚úÖ Run testing
test_dir = "/content/Alzheimers_Dataset/Combined Dataset/test"  # Replace with actual test dataset path
test_mobilenet_on_directory(test_dir)
import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# ‚úÖ Load trained models
densenet_model = load_model('densenet_best.h5')
mobilenet_model = load_model('mobilenet_best.h5')

# ‚úÖ Define class labels
CLASS_LABELS = ["Mild Impairment", "Moderate Impairment", "No Impairment", "Very Mild Impairment"]

# ‚úÖ Image preprocessing function
def preprocess_image(image_path):
    """Loads and preprocesses an image for model inference."""
    img = load_img(image_path, target_size=(224, 224))  # Resize
    img_array = img_to_array(img) / 255.0  # Normalize
    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension
    return img_array

# ‚úÖ Function to test a given model
def test_model(model, model_name, test_dir):
    """Tests a model on all images in the test directory and computes accuracy & confusion matrix."""
    true_labels = []
    predicted_labels = []

    for class_label in os.listdir(test_dir):  # Iterate through class folders
        class_dir = os.path.join(test_dir, class_label)
        if not os.path.isdir(class_dir):  # Skip non-directory files
            continue

        print(f"üîç Testing images from class: {class_label} using {model_name}...")

        for image_name in os.listdir(class_dir):
            image_path = os.path.join(class_dir, image_name)

            # Skip non-image files
            if not image_path.lower().endswith(('.png', '.jpg', '.jpeg')):
                continue

            img_array = preprocess_image(image_path)
            prediction = model.predict(img_array)
            predicted_class = np.argmax(prediction, axis=1)[0]

            true_labels.append(class_label)
            predicted_labels.append(CLASS_LABELS[predicted_class])

    # ‚úÖ Convert string labels to numerical for confusion matrix
    true_labels_num = [CLASS_LABELS.index(label) for label in true_labels]
    predicted_labels_num = [CLASS_LABELS.index(label) for label in predicted_labels]

    # ‚úÖ Compute accuracy
    accuracy = accuracy_score(true_labels, predicted_labels)
    print(f"\n‚úÖ Overall Accuracy for {model_name}: {round(accuracy * 100, 2)}%")

    # ‚úÖ Generate classification report
    print(f"\nüîç Classification Report for {model_name}:\n", classification_report(true_labels, predicted_labels))

    # ‚úÖ Compute confusion matrix
    cm = confusion_matrix(true_labels_num, predicted_labels_num)

    # ‚úÖ Plot confusion matrix
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=CLASS_LABELS, yticklabels=CLASS_LABELS)
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.title(f'Confusion Matrix - {model_name}')
    plt.show()

    # ‚úÖ Save results to CSV
    results_df = pd.DataFrame({'True Label': true_labels, 'Predicted Label': predicted_labels})
    results_df.to_csv(f'{model_name}_results.csv', index=False)
    print(f"‚úÖ Results saved to {model_name}_results.csv\n")

# ‚úÖ Run batch testing for both models
test_dir = "/content/Alzheimers_Dataset/Combined Dataset/test"  # Replace with actual path to test dataset
test_model(densenet_model, "DenseNet", test_dir)
test_model(mobilenet_model, "MobileNet", test_dir)
import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# ‚úÖ Load trained models
densenet_model = load_model('densenet_best.h5')
mobilenet_model = load_model('mobilenet_best.h5')

# ‚úÖ Define class labels
CLASS_LABELS = ["Mild Impairment", "Moderate Impairment", "No Impairment", "Very Mild Impairment"]

# ‚úÖ Image preprocessing function
def preprocess_image(image_path):
    """Loads and preprocesses an image for model inference."""
    img = load_img(image_path, target_size=(224, 224))  # Resize
    img_array = img_to_array(img) / 255.0  # Normalize
    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension
    return img_array

# ‚úÖ Ensemble Prediction function
def ensemble_predict(image_path, W1=0.6, W2=0.4):
    """Predicts class label using both DenseNet and MobileNet with weighted averaging."""
    img_array = preprocess_image(image_path)

    pred_densenet = densenet_model.predict(img_array)
    pred_mobilenet = mobilenet_model.predict(img_array)

    # Weighted averaging
    final_pred = (W1 * pred_densenet) + (W2 * pred_mobilenet)
    predicted_class = np.argmax(final_pred, axis=1)[0]

    return CLASS_LABELS[predicted_class]

# ‚úÖ Batch Testing for Ensemble Model
def test_ensemble(test_dir, W1=0.6, W2=0.4):
    """Tests ensemble model on all images in the test directory and computes accuracy & confusion matrix."""
    true_labels = []
    predicted_labels = []

    for class_label in os.listdir(test_dir):  # Iterate through class folders
        class_dir = os.path.join(test_dir, class_label)
        if not os.path.isdir(class_dir):  # Skip non-directory files
            continue

        print(f"üîç Testing images from class: {class_label} using Ensemble Model...")

        for image_name in os.listdir(class_dir):
            image_path = os.path.join(class_dir, image_name)

            # Skip non-image files
            if not image_path.lower().endswith(('.png', '.jpg', '.jpeg')):
                continue

            predicted_label = ensemble_predict(image_path, W1, W2)
            true_labels.append(class_label)
            predicted_labels.append(predicted_label)

    # ‚úÖ Convert string labels to numerical for confusion matrix
    true_labels_num = [CLASS_LABELS.index(label) for label in true_labels]
    predicted_labels_num = [CLASS_LABELS.index(label) for label in predicted_labels]

    # ‚úÖ Compute accuracy
    accuracy = accuracy_score(true_labels, predicted_labels)
    print(f"\n‚úÖ Overall Accuracy for Ensemble Model: {round(accuracy * 100, 2)}%")

    # ‚úÖ Generate classification report
    print(f"\nüîç Classification Report for Ensemble Model:\n", classification_report(true_labels, predicted_labels))

    # ‚úÖ Compute confusion matrix
    cm = confusion_matrix(true_labels_num, predicted_labels_num)

    # ‚úÖ Plot confusion matrix
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=CLASS_LABELS, yticklabels=CLASS_LABELS)
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.title('Confusion Matrix - Ensemble Model')
    plt.show()

    # ‚úÖ Save results to CSV
    results_df = pd.DataFrame({'True Label': true_labels, 'Predicted Label': predicted_labels})
    results_df.to_csv('Ensemble_Model_Results.csv', index=False)
    print("‚úÖ Results saved to Ensemble_Model_Results.csv\n")

# ‚úÖ Run ensemble model testing
test_dir = "/content/Alzheimers_Dataset/Combined Dataset/test"  # Replace with actual path to test dataset
test_ensemble(test_dir)
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import load_img, img_to_array
import albumentations as A

# ‚úÖ Load trained models
densenet_model = load_model('densenet_best.h5')
mobilenet_model = load_model('mobilenet_best.h5')

# ‚úÖ Define class labels (adjust if needed)
CLASS_LABELS = ["Mild Dementia", "Moderate Dementia", "Non Demented", "Very Mild Dementia"]

# ‚úÖ Image preprocessing function
def preprocess_image(image_path):
    """Loads and preprocesses image for model inference."""
    img = load_img(image_path, target_size=(224, 224))
    img_array = img_to_array(img) / 255.0  # Normalize
    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension
    return img_array

# ‚úÖ Prediction function using ensemble
def predict_image(image_path, W1=0.6, W2=0.4):
    """Predicts class label using both DenseNet and MobileNet with weighted averaging, including probability."""
    img_array = preprocess_image(image_path)

    pred_densenet = densenet_model.predict(img_array)
    pred_mobilenet = mobilenet_model.predict(img_array)

    # Weighted averaging
    final_pred = (W1 * pred_densenet) + (W2 * pred_mobilenet)
    predicted_class = np.argmax(final_pred, axis=1)[0]
    probability = np.max(final_pred, axis=1)[0]  # Get probability of predicted class

    return CLASS_LABELS[predicted_class], probability

# ‚úÖ Define Albumentations augmentations for TTA
augmentation = A.Compose([
    A.RandomBrightnessContrast(),
    A.GaussianBlur(),
    A.HorizontalFlip(),
    A.Rotate(limit=20)
])

# ‚úÖ Test-Time Augmentation (TTA) Prediction
def tta_predict(image_path, num_augmentations=5, W1=0.6, W2=0.4):
    """Performs multiple augmented predictions and averages the results, including probability."""
    img = load_img(image_path, target_size=(224, 224))
    img_array = img_to_array(img) / 255.0

    preds_densenet = []
    preds_mobilenet = []

    for _ in range(num_augmentations):
        aug_img = augmentation(image=img_array)['image']
        aug_img = np.expand_dims(aug_img, axis=0)

        preds_densenet.append(densenet_model.predict(aug_img))
        preds_mobilenet.append(mobilenet_model.predict(aug_img))

    avg_pred_densenet = np.mean(preds_densenet, axis=0)
    avg_pred_mobilenet = np.mean(preds_mobilenet, axis=0)

    final_pred = (W1 * avg_pred_densenet) + (W2 * avg_pred_mobilenet)
    predicted_class = np.argmax(final_pred, axis=1)[0]
    probability = np.max(final_pred, axis=1)[0]  # Get probability of predicted class

    return CLASS_LABELS[predicted_class], probability

# ‚úÖ Example usage
image_path = "/content/very mild.jpg"  # Replace with actual image path
ensemble_class, ensemble_prob = predict_image(image_path)
tta_class, tta_prob = tta_predict(image_path)

print(f"üìå Ensemble Prediction: {ensemble_class} with probability {ensemble_prob:.2f}")
print(f"üìå TTA Prediction: {tta_class} with probability {tta_prob:.2f}")
